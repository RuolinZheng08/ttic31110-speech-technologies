{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no display found. Using non-interactive Agg backend\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "from operator import itemgetter\n",
    "import pickle as pkl\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "import matplotlib as mpl\n",
    "if os.environ.get('DISPLAY','') == '':\n",
    "    print('no display found. Using non-interactive Agg backend')\n",
    "    mpl.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.seterr(divide='ignore') # masks log(0) errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hybrid.hmm.multiple import FullGaussianHMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default DNN set-up should take ~40 seconds/epoch on a GPU (and ~350 secconds/epoch on a CPU).\n",
    "\n",
    "Performance (WER) on test set:   \n",
    "\n",
    "Baseline performance of the GMM-HMM model   \n",
    "24.55%\n",
    "\n",
    "Performance of the DNN-HMM model with normalized emission probabilities   \n",
    "20.45%\n",
    "\n",
    "Performance of the DNN-HMM model with unnormalized emission probabilities   \n",
    "18.18%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a multiple digit GMM-HMM model\n",
    "NOTE: You are not expected to run/tune this part as the trained FullGaussianHMM model file is provided. The provided model is designed to have 15 states for each digit and 3 additional states for start, pause, and end. Feel free to look through hybrid/hmm/multiple.py to see how we can string single-digit HMMs to obtain the one that can model multiple-digit sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# Multiple Digit HMM: training two-digit sequences\n",
    "# \"\"\"\n",
    "# data_multiple_digit = np.load(\"hybrid/data/mfccs/mfccs_multiple.npz\", allow_pickle=True)\n",
    "# full_model = FullGaussianHMM(data_multiple_digit[\"Xtrain\"], \"hybrid/hmm/models/single_digit_model.pkl\")\n",
    "\n",
    "# n_iter = 15\n",
    "\n",
    "# print(\"Training HMM\")\n",
    "# for i in range(n_iter):\n",
    "#     print(\"starting iteration {}...\".format(i + 1))\n",
    "#     full_model.train(data_multiple_digit[\"Xtrain\"], data_multiple_digit[\"Ytrain\"])\n",
    "        \n",
    "# print(\"Testing HMM\")\n",
    "# test_wer = full_model.test(data_multiple_digit[\"Xtest\"], data_multiple_digit[\"Ytest\"])\n",
    "# print(\"{:.2f}% WER\".format(test_wer * 100.))\n",
    "\n",
    "# with open(\"hybrid/hmm/models/multiple_digit_model.pkl\", \"wb\") as f:\n",
    "#     pkl.dump(full_model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the optimal state sequences\n",
    "Save the optimal state label per framee using the trained GMM-HMM model. Complete the # TODO in force_align function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def force_align(X, Y, hmm_gmm_model):\n",
    "    \"\"\"\n",
    "    Force align using Viterbi to get the hidden state sequence for each (X, Y) pair.\n",
    "    ------\n",
    "    input:\n",
    "    X: list of 2d-arrays of shape (Tx, 13): list of single digit MFCC features\n",
    "    Y: digit sequence\n",
    "    hmm_gmm_model: load the trained model\n",
    "    ------\n",
    "    Returns a list of utterence-wise hidden state sequences\n",
    "    \"\"\"\n",
    "    digit_states_total = hmm_gmm_model.digit_states_total\n",
    "    start_states, stop_states = hmm_gmm_model.start_states, hmm_gmm_model.stop_states\n",
    "    begin_sil_id, pause_id, end_sil_id = hmm_gmm_model.begin_sil, hmm_gmm_model.pause, hmm_gmm_model.end_sil\n",
    "    A_estimate, pi_estimate = hmm_gmm_model.A, hmm_gmm_model.pi\n",
    "    state_seqs = []\n",
    "    for ii, (x, y) in enumerate(zip(X, Y)):\n",
    "\n",
    "        y = np.array([0 if yy == 'o' else int(yy) for yy in y], dtype=np.int32)\n",
    "\n",
    "        # TODO: edit A_estimate appropriately to enable decoding for the ground-truth labels\n",
    "        A_estimate[begin_sil_id] = 0\n",
    "        A_estimate[pause_id] = 0\n",
    "        for idx, yy in enumerate(y):\n",
    "            if idx == 0:\n",
    "                A_estimate[begin_sil_id, start_states[yy]] = 1\n",
    "            else:\n",
    "                A_estimate[pause_id, start_states[yy]] = 1\n",
    "            start, stop = start_states[yy], stop_states[yy]\n",
    "            A_estimate[start: stop + 1] = 0\n",
    "            A_estimate[start: stop, start + 1: stop + 1] = np.eye(stop - start)\n",
    "            if idx == len(y) - 1:\n",
    "                A_estimate[stop_states[yy], end_sil_id] = 1\n",
    "            else:\n",
    "                A_estimate[stop_states[yy], pause_id] = 1\n",
    "\n",
    "#         test_force_align(y, A_estimate, start_states, stop_states, begin_sil_id, pause_id, end_sil_id)\n",
    "\n",
    "        log_pi = np.log(pi_estimate)\n",
    "        log_A = np.log(A_estimate)\n",
    "        log_B = hmm_gmm_model.get_emissions(x)\n",
    "\n",
    "        q, log_prob = hmm_gmm_model.viterbi(log_pi, log_A, log_B) \n",
    "        state_seqs.append(q)\n",
    "\n",
    "    return state_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity-check force_align\n",
    "def test_force_align(y, mat, start_states, stop_states, begin_sil_id, pause_id, end_sil_id):\n",
    "    assert np.allclose(mat.sum(axis=1), 1)  # row-stochastic\n",
    "    for idx, yy in enumerate(y):\n",
    "        if idx == 0:\n",
    "            assert mat[begin_sil_id, start_states[yy]] == 1\n",
    "        else:\n",
    "            assert mat[pause_id, start_states[yy]] == 1\n",
    "        start, stop = start_states[yy], stop_states[yy]\n",
    "        assert np.alltrue(mat[start : stop, start + 1 : stop + 1] == np.eye(stop - start))\n",
    "        if idx == len(y) - 1:\n",
    "            assert mat[stop_states[yy], end_sil_id] == 1\n",
    "        else:\n",
    "            assert mat[stop_states[5], pause_id] == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_multiple_digit = np.load(\"hybrid/data/mfccs/mfccs_multiple.npz\", allow_pickle=True)\n",
    "# with open(\"hybrid/hmm/models/multiple_digit_model.pkl\", \"rb\") as f:\n",
    "#     hmm_gmm_model = pkl.load(f)\n",
    "    \n",
    "# state_seq_train = force_align(data_multiple_digit[\"Xtrain\"], data_multiple_digit[\"Ytrain\"], hmm_gmm_model)\n",
    "# state_seq_dev = force_align(data_multiple_digit[\"Xdev\"], data_multiple_digit[\"Ydev\"], hmm_gmm_model)\n",
    "# state_seq_test = force_align(data_multiple_digit[\"Xtest\"], data_multiple_digit[\"Ytest\"], hmm_gmm_model)\n",
    "# seqDict = {'Ytrain': state_seq_train, 'Ydev': state_seq_dev, 'Ytest': state_seq_test, 'total_states': hmm_gmm_model.total}\n",
    "# np.savez_compressed('hybrid/data/state_seq/state_seq.npz', **seqDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a DNN frame classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hybrid.dnn.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"hybrid/dnn/config.json\", \"r\") as fid:                                                                                                                                                                                                                                      \n",
    "    config = json.load(fid)\n",
    "\n",
    "np.random.seed(config[\"seed\"])\n",
    "torch.manual_seed(config[\"seed\"])\n",
    "\n",
    "data_cfg = config[\"data\"]\n",
    "model_cfg = config[\"model\"]\n",
    "opt_cfg = config[\"optimizer\"]\n",
    "out_cfg = config[\"output\"]\n",
    "save_model_fn = os.path.join(out_cfg[\"save_dir\"], \"dnn_model\")\n",
    "\n",
    "data_mfccs = np.load(data_cfg[\"mfcc\"], allow_pickle=True)\n",
    "state_seq = np.load(data_cfg[\"state_seq\"], allow_pickle=True)\n",
    "\n",
    "print(\"Preparing data...\\n\")\n",
    "data_ldr = DataLoader(data_cfg)\n",
    "train_features, train_labels, train_labels_onehot, train_utt_to_frames = data_ldr.prepare_data('train')\n",
    "dev_features, dev_labels, dev_labels_onehot, dev_utt_to_frames = data_ldr.prepare_data('dev')\n",
    "test_features, test_labels, test_labels_onehot, test_utt_to_frames = data_ldr.prepare_data('test')\n",
    "\n",
    "feat_dim = (data_ldr.context_size+1)*data_ldr.mfcc_dim\n",
    "n_states = data_ldr.n_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "\n",
    "    def __init__(self, feat_dim, n_states, hidden_dim, n_layers, dropout):\n",
    "        \"\"\"\n",
    "        Initialized feed forward neural network model.\n",
    "        ---\n",
    "        feat_dim: input feature dimension\n",
    "        n_states: size of the output\n",
    "        hidden_dim: dimension of the hidden layers\n",
    "        n_layers: number of layers\n",
    "        dropout: dropout probabilty for the dropout layer\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_layers = n_layers\n",
    "        self.fc_input = nn.Linear(feat_dim, hidden_dim)\n",
    "        self.fc_output = nn.Linear(hidden_dim, n_states)\n",
    "        self.fc_hidden_list = nn.ModuleList([nn.Linear(hidden_dim, hidden_dim)]*n_layers)\n",
    "        self.nl = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass for the feedforward network\n",
    "        \"\"\"\n",
    "        x = self.nl(self.fc_input(x))\n",
    "        for i in range(self.n_layers):\n",
    "            x = self.nl(self.fc_hidden_list[i](x))\n",
    "        output = F.leaky_relu(self.fc_output(x))\n",
    "\n",
    "        return output\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(classifier, epoch, batch_size, device, loss_func, optim):\n",
    "    \"\"\"\n",
    "    Training the classifier on frame level labels\n",
    "    \"\"\"\n",
    "    classifier.train()\n",
    "    perm = np.random.permutation(train_features.shape[0])\n",
    "    train_loss, pred_multi, gt_multi = [], [], []\n",
    "    n_iter = 0\n",
    "    start = time.time()\n",
    "    time_per_iter = [0]*4\n",
    "    for i in range(0, len(perm), batch_size):\n",
    "        idx = perm[i:i+batch_size]\n",
    "        train_Xs = torch.tensor(train_features[idx], dtype=torch.float32).to(device)\n",
    "        train_Ys = torch.tensor(train_labels[idx], dtype=torch.long).to(device)\n",
    "        pred_Ys = classifier(train_Xs)\n",
    "        loss = loss_func(pred_Ys, train_Ys)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(classifier.parameters(), 5.0)\n",
    "        optim.step()\n",
    "        train_loss.append(loss.cpu().item())\n",
    "        pred_multi.append(np.argmax(pred_Ys.cpu().data.numpy(), axis=1))\n",
    "        gt_multi.append(train_Ys.cpu().data.numpy())\n",
    "    pred_multi, gt_multi = np.concatenate(pred_multi, axis=0), np.concatenate(gt_multi, axis=0)\n",
    "    accuracy = 100*len(np.where((pred_multi - gt_multi)==0)[0])/len(pred_multi)\n",
    "    mean_loss = np.mean(train_loss)\n",
    "    print(\"Epoch: %d, Training loss: %.2f, Accuracy: %.2f, Time elapsed: %.2f seconds\" % (epoch, mean_loss, accuracy, time.time() - start))\n",
    "\n",
    "    return accuracy, mean_loss\n",
    "\n",
    "def test(features, labels, test_batch_size, device, loss_func, classifier_test=None):\n",
    "    \"\"\"\n",
    "    Training the classifier on frame level labels\n",
    "    \"\"\"\n",
    "    if classifier_test is None:\n",
    "        classifier_test = torch.load(save_model_fn)\n",
    "    classifier_test.eval()\n",
    "    test_loss, pred_multi, gt_multi = [], [], []\n",
    "    n_iter = 0\n",
    "    start = time.time()\n",
    "    for i in range(0, len(features), test_batch_size):\n",
    "        n_iter += 1\n",
    "        idx = list(range(i, min(i+test_batch_size, len(features))))\n",
    "        test_Xs = torch.tensor(features[idx], dtype=torch.float32).to(device)\n",
    "        test_Ys = torch.tensor(labels[idx], dtype=torch.long).to(device)\n",
    "        pred_Ys = classifier_test(test_Xs)\n",
    "        loss = loss_func(pred_Ys, test_Ys)\n",
    "        test_loss.append(loss.cpu().item())\n",
    "        pred_multi.append(np.argmax(pred_Ys.cpu().data.numpy(), axis=1))\n",
    "        gt_multi.append(test_Ys.cpu().data.numpy())\n",
    "\n",
    "    pred_multi, gt_multi = np.concatenate(pred_multi, axis=0), np.concatenate(gt_multi, axis=0)\n",
    "    accuracy = 100*len(np.where((pred_multi - gt_multi)==0)[0])/len(pred_multi)\n",
    "\n",
    "    print(\"Dev Accuracy: %.2f, Time elapsed: %.2f seconds\" % (accuracy, time.time() - start))\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "def main_train(classifier, batch_size, test_batch_size, tot_epoch, device, loss_func, optim, meta):\n",
    "    print(\"Training begins ...\\n\")\n",
    "    best_accuracy = 0\n",
    "    plotting = {'train_loss': [], 'train_accu': [], 'dev_accu': []}\n",
    "    for epoch in range(tot_epoch):\n",
    "        train_accuracy, train_loss = train(classifier, epoch, batch_size, device, \n",
    "                                           loss_func, optim)\n",
    "        dev_accuracy = test(dev_features, dev_labels, test_batch_size, device, loss_func, classifier)\n",
    "        print('Epoch {}: train_loss: {}, train_accuracy: {}, dev_accuracy: {}'.format(\n",
    "            epoch, train_loss, train_accuracy, dev_accuracy))\n",
    "        \n",
    "        plotting['train_loss'].append(train_loss)\n",
    "        plotting['train_accu'].append(train_accuracy)\n",
    "        plotting['dev_accu'].append(dev_accuracy)\n",
    "        \n",
    "        if dev_accuracy > best_accuracy:\n",
    "            best_epoch = epoch\n",
    "            best = '{}-{}.pkl'.format(save_model_fn, meta)\n",
    "            torch.save(classifier, best)\n",
    "            print('Saved model:', best)\n",
    "            best_accuracy = dev_accuracy\n",
    "    print('\\nBest dev accuracy: %.2f at epoch: %d' % (best_accuracy, best_epoch))\n",
    "    return plotting\n",
    "\n",
    "def main_test(test_batch_size, device):\n",
    "    accuracy = test(test_features, test_labels, device, test_batch_size, loss_func)\n",
    "    print('\\nAccuracy on test set: %.2sf' % (accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting helper\n",
    "def plot_loss_accu(best, plotting, xlabel='# epochs', xticks=None):\n",
    "    plt.suptitle(best)\n",
    "    plt.subplot(1, 2, 1)\n",
    "    if xticks is None:\n",
    "        plt.plot(plotting['train_loss'], label='train_loss')\n",
    "    else:\n",
    "        plt.plot(xticks, plotting['train_loss'], label='train_loss')\n",
    "    plt.legend()\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel('train_loss')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    if xticks is None:\n",
    "        plt.plot(plotting['dev_accu'], label='dev_accu')\n",
    "        plt.plot(plotting['train_accu'], label='train_accu')\n",
    "    else:\n",
    "        plt.plot(xticks, plotting['dev_accu'], label='dev_accu')\n",
    "        plt.plot(xticks, plotting['train_accu'], label='train_accu')    \n",
    "    plt.legend()\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.85)\n",
    "    plt.savefig('figures/' + best + '.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: tune on the dev set\n",
    "# may want to set up function or chunk of code here to perform tuning\n",
    "# call train on training set, call test on dev, save/plot/compare results\n",
    "def tune(hyperparams):\n",
    "    tot_epoch = opt_cfg[\"max_epochs\"]\n",
    "    hidden_dim = hyperparams.get('hidden_dim', model_cfg[\"hidden_dim\"])\n",
    "    n_layers = hyperparams.get('n_layers', model_cfg[\"n_layers\"])\n",
    "    dropout = hyperparams.get('dropout_prob', model_cfg[\"dropout_probability\"])\n",
    "\n",
    "    batch_size = hyperparams.get('batch_size', opt_cfg[\"batch_size\"])\n",
    "    test_batch_size = opt_cfg[\"test_batch_size\"]\n",
    "    \n",
    "    print('\\n\\nModel Configuration ep {}, hid {}, n_layers {}, dropout {}, batch {}'.format(\n",
    "    tot_epoch, hidden_dim, n_layers, dropout, batch_size))\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    if device == 'cuda':\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "    classifier = FeedForward(feat_dim, n_states, hidden_dim, n_layers, dropout).to(device)\n",
    "    # classifier.apply(init_weights)\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    optimizer = getattr(torch.optim, opt_cfg[\"type\"])(list(classifier.parameters()))\n",
    "\n",
    "    meta = '+'.join([str(elm) for elm in [tot_epoch, hidden_dim, n_layers, dropout, batch_size]])\n",
    "    plotting = main_train(classifier, batch_size, test_batch_size, tot_epoch, device, \n",
    "               loss_function, optimizer, meta)\n",
    "    \n",
    "    return meta, plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss and Accuracy vs. Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# default config\n",
    "best, plotting = tune({})\n",
    "plot_loss_accu(best, plotting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(param_name, param_range):\n",
    "    data = {'train_loss': [], 'train_accu': [], 'dev_accu': []}\n",
    "    for param in param_range:\n",
    "        hp = {param_name: param}\n",
    "        _, plotting = tune(hp)\n",
    "        # record best dev accuracy\n",
    "        idx = np.argmax(plotting['dev_accu'])\n",
    "        for k in data:\n",
    "            data[k].append(plotting[k][idx])\n",
    "    #     plot_wer_loss(best, plotting)\n",
    "    plot_loss_accu(param_name, data, xlabel=param_name, xticks=param_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Model Configuration ep 10, hid 512, n_layers 1, dropout 0.2, batch 8\n",
      "Training begins ...\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-5a6b79bf1618>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# tune dropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mexperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dropout_prob'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-62-331095e5da9a>\u001b[0m in \u001b[0;36mexperiment\u001b[0;34m(param_name, param_range)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparam_range\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mhp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mparam_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplotting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;31m# record best dev accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplotting\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dev_accu'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-eb3f23b4b2b1>\u001b[0m in \u001b[0;36mtune\u001b[0;34m(hyperparams)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_cfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"type\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     plotting = main_train(classifier, batch_size, test_batch_size, tot_epoch, device, \n\u001b[0m\u001b[1;32m     28\u001b[0m                loss_function, optimizer)\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-58675e30974b>\u001b[0m in \u001b[0;36mmain_train\u001b[0;34m(classifier, batch_size, test_batch_size, tot_epoch, device, loss_func, optim)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mplotting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'train_accu'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dev_accu'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtot_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         dev_accuracy = test(dev_features, dev_labels, test_batch_size, device, loss_func,\n\u001b[1;32m     65\u001b[0m                             classifier=classifier)\n",
      "\u001b[0;32m<ipython-input-32-58675e30974b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(classifier, epoch, batch_size, device, loss_func, optim)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtrain_Xs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mtrain_Ys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mpred_Ys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_Xs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_Ys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Ys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-2da37ae88113>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_hidden_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mleaky_relu\u001b[0;34m(input, negative_slope, inplace)\u001b[0m\n\u001b[1;32m   1237\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1240\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# tune dropout\n",
    "experiment('dropout_prob', [0.2, 0.4, 0.6, 0.8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # tune n_layers\n",
    "# experiment('n_layers', [1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save log-emission probabilities using the best model saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_emission(utt_to_frames_dict, features, prior, temp_parameter, best_model_path):\n",
    "    \"\"\"\n",
    "    Save posteriors using the trained model\n",
    "    \"\"\"\n",
    "    classifier_eval = torch.load(best_model_path)\n",
    "    classifier_eval.eval()\n",
    "    log_emission = []\n",
    "    n_iter = 0\n",
    "    for utt_idx in range(len(utt_to_frames_dict)):\n",
    "        frame_id = utt_to_frames_dict[utt_idx]\n",
    "        log_emission_utt = []\n",
    "        for i in range(0, len(frame_id), batch_size):\n",
    "            idx = frame_id[i:i+batch_size]\n",
    "            Xs = torch.tensor(itemgetter(*idx)(features), dtype=torch.float32).to(device)\n",
    "            log_pred_Ys = F.log_softmax(classifier_eval(Xs), dim=1).cpu().data.numpy()\n",
    "            log_emission_utt.append(log_pred_Ys  - temp_parameter*np.log(prior))\n",
    "        log_emission_utt = np.concatenate(log_emission_utt, axis=0)\n",
    "        log_emission.append(log_emission_utt)\n",
    "\n",
    "    return log_emission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_parameter = out_cfg[\"temp_parameter\"]\n",
    "# print(\"Saving log emissions for temperature %.1f ...\\n\" % (temp_parameter))\n",
    "# prior = data_ldr.get_prior()\n",
    "# train_log_emission =  get_log_emission(train_utt_to_frames, train_features, prior, temp_parameter, save_model_fn)\n",
    "# dev_log_emission = get_log_emission(dev_utt_to_frames, dev_features, prior, temp_parameter, save_model_fn)\n",
    "# test_log_emission = get_log_emission(test_utt_to_frames, test_features, prior, temp_parameter, save_model_fn)\n",
    "# log_emission_dict = {'Ytrain': train_log_emission, 'Ydev': dev_log_emission, 'Ytest': test_log_emission}\n",
    "# np.savez_compressed(os.path.join('hybrid/data/log_emission/log_emission_'+str(temp_parameter)+'.npz'), **log_emission_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HMM inference using the posterior from neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_multiple_digit = np.load(\"hybrid/data/mfccs/mfccs_multiple.npz\", allow_pickle=True)\n",
    "\n",
    "# with open(\"hybrid/hmm/models/multiple_digit_model.pkl\", \"rb\") as f:\n",
    "#     full_model_trained = pkl.load(f)\n",
    "\n",
    "# log_emission_1 = np.load('hybrid/data/log_emission/log_emission_1.0.npz', allow_pickle=True)\n",
    "# log_emission_0 = np.load('hybrid/data/log_emission/log_emission_0.0.npz', allow_pickle=True)\n",
    "    \n",
    "# def get_test_wer(model, posterior=None):\n",
    "#     test_wer = model.test(data_multiple_digit[\"Xtest\"], data_multiple_digit[\"Ytest\"], posterior)\n",
    "#     print(\"{:.2f}% TEST WER\".format(test_wer * 100.))\n",
    "\n",
    "# print('Baseline performance of the trained model')\n",
    "# get_test_wer(full_model_trained)\n",
    "\n",
    "# print('Performance of the trained model with normalized emission probabilities')\n",
    "# get_test_wer(full_model_trained, log_emission_1[\"Ytest\"])\n",
    "\n",
    "# print('Performance of the trained model with unnormalized emission probabilities')\n",
    "# get_test_wer(full_model_trained, log_emission_0[\"Ytest\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
