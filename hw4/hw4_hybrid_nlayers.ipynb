{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'invalid': 'warn', 'over': 'warn', 'under': 'ignore'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "from operator import itemgetter\n",
    "import os\n",
    "import pickle as pkl\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.seterr(divide='ignore') # masks log(0) errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hybrid.hmm.multiple import FullGaussianHMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default DNN set-up should take ~40 seconds/epoch on a GPU (and ~350 secconds/epoch on a CPU).\n",
    "\n",
    "Performance (WER) on test set:   \n",
    "\n",
    "Baseline performance of the GMM-HMM model   \n",
    "24.55%\n",
    "\n",
    "Performance of the DNN-HMM model with normalized emission probabilities   \n",
    "20.45%\n",
    "\n",
    "Performance of the DNN-HMM model with unnormalized emission probabilities   \n",
    "18.18%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a multiple digit GMM-HMM model\n",
    "NOTE: You are not expected to run/tune this part as the trained FullGaussianHMM model file is provided. The provided model is designed to have 15 states for each digit and 3 additional states for start, pause, and end. Feel free to look through hybrid/hmm/multiple.py to see how we can string single-digit HMMs to obtain the one that can model multiple-digit sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# Multiple Digit HMM: training two-digit sequences\n",
    "# \"\"\"\n",
    "# data_multiple_digit = np.load(\"hybrid/data/mfccs/mfccs_multiple.npz\", allow_pickle=True)\n",
    "# full_model = FullGaussianHMM(data_multiple_digit[\"Xtrain\"], \"hybrid/hmm/models/single_digit_model.pkl\")\n",
    "\n",
    "# n_iter = 15\n",
    "\n",
    "# print(\"Training HMM\")\n",
    "# for i in range(n_iter):\n",
    "#     print(\"starting iteration {}...\".format(i + 1))\n",
    "#     full_model.train(data_multiple_digit[\"Xtrain\"], data_multiple_digit[\"Ytrain\"])\n",
    "        \n",
    "# print(\"Testing HMM\")\n",
    "# test_wer = full_model.test(data_multiple_digit[\"Xtest\"], data_multiple_digit[\"Ytest\"])\n",
    "# print(\"{:.2f}% WER\".format(test_wer * 100.))\n",
    "\n",
    "# with open(\"hybrid/hmm/models/multiple_digit_model.pkl\", \"wb\") as f:\n",
    "#     pkl.dump(full_model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the optimal state sequences\n",
    "Save the optimal state label per framee using the trained GMM-HMM model. Complete the # TODO in force_align function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def force_align(X, Y, hmm_gmm_model):\n",
    "    \"\"\"\n",
    "    Force align using Viterbi to get the hidden state sequence for each (X, Y) pair.\n",
    "    ------\n",
    "    input:\n",
    "    X: list of 2d-arrays of shape (Tx, 13): list of single digit MFCC features\n",
    "    Y: digit sequence\n",
    "    hmm_gmm_model: load the trained model\n",
    "    ------\n",
    "    Returns a list of utterence-wise hidden state sequences\n",
    "    \"\"\"\n",
    "    start_states, stop_states = hmm_gmm_model.start_states, hmm_gmm_model.stop_states\n",
    "    begin_sil_id, pause_id, end_sil_id = hmm_gmm_model.begin_sil, hmm_gmm_model.pause, hmm_gmm_model.end_sil\n",
    "    A_estimate, pi_estimate = hmm_gmm_model.A, hmm_gmm_model.pi\n",
    "    state_seqs = []\n",
    "    for ii, (x, y) in enumerate(zip(X, Y)):\n",
    "\n",
    "        y = np.array([0 if yy == 'o' else int(yy) for yy in y], dtype=np.int32)\n",
    "\n",
    "        # TODO: edit A_estimate appropriately to enable decoding for the ground-truth labelss\n",
    "        y1, y2 = y\n",
    "        stop_y1, stop_y2 = stop_states[y1], stop_states[y2]\n",
    "        # begin to the start state of y1, preserve some self-transitioning prob for begin\n",
    "        temp = A_estimate[begin_sil_id, begin_sil_id]\n",
    "        A_estimate[begin_sil_id] = 0\n",
    "        A_estimate[begin_sil_id, begin_sil_id] = temp\n",
    "        A_estimate[begin_sil_id, start_states[y1]] = 1 - temp\n",
    "        # stop state of y1 to pause, preserve self\n",
    "        temp = A_estimate[stop_states[y1], stop_states[y1]]\n",
    "        A_estimate[stop_states[y1]] = 0\n",
    "        A_estimate[stop_states[y1], stop_states[y1]] = temp\n",
    "        A_estimate[stop_states[y1], pause_id] = 1 - temp\n",
    "        # pause to the start state of y2, preserve some self-transitioning prob for pause\n",
    "        temp = A_estimate[pause_id, pause_id]\n",
    "        A_estimate[pause_id] = 0\n",
    "        A_estimate[pause_id, pause_id] = temp\n",
    "        A_estimate[pause_id, start_states[y2]] = 1 - temp\n",
    "        # stop state of y2 to end_sil, preserve self\n",
    "        temp = A_estimate[stop_states[y2], stop_states[y2]]\n",
    "        A_estimate[stop_states[y2]] = 0\n",
    "        A_estimate[stop_states[y2], stop_states[y2]] = temp\n",
    "        A_estimate[stop_states[y2], end_sil_id] = 1 - temp\n",
    "        \n",
    "        log_pi = np.log(pi_estimate)\n",
    "        log_A = np.log(A_estimate)\n",
    "        log_B = hmm_gmm_model.get_emissions(x)\n",
    "\n",
    "        q, log_prob = hmm_gmm_model.viterbi(log_pi, log_A, log_B) \n",
    "        state_seqs.append(q)\n",
    "\n",
    "    return state_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('hybrid/data/state_seq/state_seq.npz'):\n",
    "    data_multiple_digit = np.load(\"hybrid/data/mfccs/mfccs_multiple.npz\", allow_pickle=True)\n",
    "    with open(\"hybrid/hmm/models/multiple_digit_model.pkl\", \"rb\") as f:\n",
    "        hmm_gmm_model = pkl.load(f)\n",
    "\n",
    "    state_seq_train = force_align(data_multiple_digit[\"Xtrain\"], data_multiple_digit[\"Ytrain\"], hmm_gmm_model)\n",
    "    state_seq_dev = force_align(data_multiple_digit[\"Xdev\"], data_multiple_digit[\"Ydev\"], hmm_gmm_model)\n",
    "    state_seq_test = force_align(data_multiple_digit[\"Xtest\"], data_multiple_digit[\"Ytest\"], hmm_gmm_model)\n",
    "    seqDict = {'Ytrain': state_seq_train, 'Ydev': state_seq_dev, 'Ytest': state_seq_test, 'total_states': hmm_gmm_model.total}\n",
    "    np.savez_compressed('hybrid/data/state_seq/state_seq.npz', **seqDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a DNN frame classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hybrid.dnn.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global config, not yet overridden\n",
    "with open(\"hybrid/dnn/config.json\", \"r\") as fid:                                                                                                                                                                                                                                      \n",
    "    config = json.load(fid)\n",
    "\n",
    "np.random.seed(config[\"seed\"])\n",
    "torch.manual_seed(config[\"seed\"])\n",
    "\n",
    "data_cfg = config[\"data\"]\n",
    "model_cfg = config[\"model\"]\n",
    "opt_cfg = config[\"optimizer\"]\n",
    "out_cfg = config[\"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing data...\\n\")\n",
    "data_mfccs = np.load(data_cfg[\"mfcc\"], allow_pickle=True)\n",
    "state_seq = np.load(data_cfg[\"state_seq\"], allow_pickle=True)\n",
    "\n",
    "data_ldr = DataLoader(data_cfg)\n",
    "train_features, train_labels, train_labels_onehot, train_utt_to_frames = data_ldr.prepare_data('train')\n",
    "dev_features, dev_labels, dev_labels_onehot, dev_utt_to_frames = data_ldr.prepare_data('dev')\n",
    "test_features, test_labels, test_labels_onehot, test_utt_to_frames = data_ldr.prepare_data('test')\n",
    "\n",
    "feat_dim = (data_ldr.context_size+1)*data_ldr.mfcc_dim\n",
    "n_states = data_ldr.n_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "\n",
    "    def __init__(self, feat_dim, n_states, hidden_dim, n_layers, dropout):\n",
    "        \"\"\"\n",
    "        Initialized feed forward neural network model.\n",
    "        ---\n",
    "        feat_dim: input feature dimension\n",
    "        n_states: size of the output\n",
    "        hidden_dim: dimension of the hidden layers\n",
    "        n_layers: number of layers\n",
    "        dropout: dropout probabilty for the dropout layer\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_layers = n_layers\n",
    "        self.fc_input = nn.Linear(feat_dim, hidden_dim)\n",
    "        self.fc_output = nn.Linear(hidden_dim, n_states)\n",
    "        self.fc_hidden_list = nn.ModuleList([nn.Linear(hidden_dim, hidden_dim)]*n_layers)\n",
    "        self.nl = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass for the feedforward network\n",
    "        \"\"\"\n",
    "        x = self.nl(self.fc_input(x))\n",
    "        for i in range(self.n_layers):\n",
    "            x = self.nl(self.fc_hidden_list[i](x))\n",
    "        output = F.leaky_relu(self.fc_output(x))\n",
    "\n",
    "        return output\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(classifier, optimizer):\n",
    "    \"\"\"\n",
    "    Training the classifier on frame level labels\n",
    "    \"\"\"\n",
    "    classifier.train()\n",
    "    perm = np.random.permutation(train_features.shape[0])\n",
    "    train_loss, pred_multi, gt_multi = [], [], []\n",
    "    n_iter = 0\n",
    "    start = time.time()\n",
    "    time_per_iter = [0]*4\n",
    "    for i in range(0, len(perm), batch_size):\n",
    "        idx = perm[i:i+batch_size]\n",
    "        train_Xs = torch.tensor(train_features[idx], dtype=torch.float32).to(device)\n",
    "        train_Ys = torch.tensor(train_labels[idx], dtype=torch.long).to(device)\n",
    "        pred_Ys = classifier(train_Xs)\n",
    "        loss = loss_function(pred_Ys, train_Ys)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(classifier.parameters(), 5.0)\n",
    "        optimizer.step()\n",
    "        train_loss.append(loss.cpu().item())\n",
    "        pred_multi.append(np.argmax(pred_Ys.cpu().data.numpy(), axis=1))\n",
    "        gt_multi.append(train_Ys.cpu().data.numpy())\n",
    "    pred_multi, gt_multi = np.concatenate(pred_multi, axis=0), np.concatenate(gt_multi, axis=0)\n",
    "    accuracy = 100*len(np.where((pred_multi - gt_multi)==0)[0])/len(pred_multi)\n",
    "    print(\"Training time elapsed: %.2f seconds\" % (time.time() - start))\n",
    "    return accuracy, np.mean(train_loss)\n",
    "\n",
    "def test(features, labels, classifier_test=None):\n",
    "    \"\"\"\n",
    "    Training the classifier on frame level labels\n",
    "    \"\"\"\n",
    "    if classifier_test is None:\n",
    "        classifier_test = torch.load(save_model_fn)\n",
    "    classifier_test.eval()\n",
    "    test_loss, pred_multi, gt_multi = [], [], []\n",
    "    n_iter = 0\n",
    "    start = time.time()\n",
    "    for i in range(0, len(features), test_batch_size):\n",
    "        n_iter += 1\n",
    "        idx = list(range(i, min(i+test_batch_size, len(features))))\n",
    "        test_Xs = torch.tensor(features[idx], dtype=torch.float32).to(device)\n",
    "        test_Ys = torch.tensor(labels[idx], dtype=torch.long).to(device)\n",
    "        pred_Ys = classifier_test(test_Xs)\n",
    "        loss = loss_function(pred_Ys, test_Ys)\n",
    "        test_loss.append(loss.cpu().item())\n",
    "        pred_multi.append(np.argmax(pred_Ys.cpu().data.numpy(), axis=1))\n",
    "        gt_multi.append(test_Ys.cpu().data.numpy())\n",
    "\n",
    "    pred_multi, gt_multi = np.concatenate(pred_multi, axis=0), np.concatenate(gt_multi, axis=0)\n",
    "    accuracy = 100*len(np.where((pred_multi - gt_multi)==0)[0])/len(pred_multi)\n",
    "    print(\"Dev elapsed: %.2f seconds\" % (time.time() - start))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_train(classifier, optimizer, curr_config):\n",
    "    plotting = {'train_loss': [], 'train_accu': [], 'dev_accu': []}\n",
    "    global global_best_accu\n",
    "    best_accuracy = 0\n",
    "    for epoch in range(tot_epoch):\n",
    "        train_accuracy, loss = train(classifier, optimizer)\n",
    "        dev_accuracy = test(dev_features, dev_labels, classifier)\n",
    "        print(\"Epoch: %d, Training loss: %.2f, Accuracy: %.2f, Dev Accuracy: %.2f\" % \n",
    "              (epoch, loss, train_accuracy, dev_accuracy))\n",
    "        \n",
    "        plotting['train_loss'].append(loss)\n",
    "        plotting['train_accu'].append(train_accuracy)\n",
    "        plotting['dev_accu'].append(dev_accuracy)\n",
    "        \n",
    "        if dev_accuracy > global_best_accu:\n",
    "            best_epoch = epoch\n",
    "            torch.save(classifier, save_model_fn) # global dnn-model.pkl\n",
    "            global_best_accu = dev_accuracy\n",
    "        if dev_accuracy > best_accuracy: # save temporarily\n",
    "            best_epoch = epoch\n",
    "            torch.save(classifier, os.path.join(out_cfg[\"save_dir\"], curr_config))\n",
    "            best_accuracy = dev_accuracy\n",
    "    print('\\nBest dev accuracy: %.2f at epoch: %d' % (best_accuracy, best_epoch))\n",
    "    return plotting\n",
    "\n",
    "def main_test():\n",
    "    accuracy = test(test_features, test_labels)\n",
    "    print('\\nAccuracy on test set: %.2sf' % (accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more global config\n",
    "tot_epoch = opt_cfg[\"max_epochs\"]\n",
    "batch_size = opt_cfg[\"batch_size\"]\n",
    "test_batch_size = opt_cfg[\"test_batch_size\"]\n",
    "\n",
    "save_model_fn = os.path.join(out_cfg[\"save_dir\"], \"dnn_model.pkl\")\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "if device == 'cuda':\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: tune on the dev set\n",
    "# may want to set up function or chunk of code here to perform tuning\n",
    "# call train on training set, call test on dev, save/plot/compare results\n",
    "global_best_accu = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting helper\n",
    "def plot_loss_accu(best, plotting, xlabel='# epochs', xticks=None):\n",
    "    plt.suptitle(best)\n",
    "    plt.subplot(1, 2, 1)\n",
    "    if xticks is None:\n",
    "        plt.plot(plotting['train_loss'], label='train_loss')\n",
    "    else:\n",
    "        plt.plot(xticks, plotting['train_loss'], label='train_loss')\n",
    "    plt.legend()\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel('train_loss')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    if xticks is None:\n",
    "        plt.plot(plotting['dev_accu'], label='dev_accu')\n",
    "        plt.plot(plotting['train_accu'], label='train_accu')\n",
    "    else:\n",
    "        plt.plot(xticks, plotting['dev_accu'], label='dev_accu')\n",
    "        plt.plot(xticks, plotting['train_accu'], label='train_accu')    \n",
    "    plt.legend()\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.85)\n",
    "    plt.savefig('figures/' + best + '.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune(hyperparams):    \n",
    "    hidden_dim = hyperparams.get('hidden_dim', model_cfg[\"hidden_dim\"])\n",
    "    n_layers = hyperparams.get('n_layers', model_cfg[\"n_layers\"])\n",
    "    dropout = hyperparams.get('dropout', model_cfg[\"dropout_probability\"])\n",
    "    \n",
    "    curr_config = 'hid{}+n_layers{}+dropout{}'.format(hidden_dim, n_layers, dropout)\n",
    "    print('\\nTraining DNN with config:', curr_config)\n",
    "    classifier = FeedForward(feat_dim, n_states, hidden_dim, n_layers, dropout).to(device)\n",
    "    # classifier.apply(init_weights)\n",
    "    optimizer = getattr(torch.optim, opt_cfg[\"type\"])(list(classifier.parameters()))\n",
    "\n",
    "    plotting = main_train(classifier, optimizer, curr_config)\n",
    "    return curr_config, plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (e) i. Plots of the loss and accuracy vs. epoch on train and dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # default config\n",
    "# plt_title, plotting = tune({})\n",
    "# plot_loss_accu(plt_title, plotting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (e) ii. For models trained with dropout 0.3, 0.5, 0.8, plot loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(param_name, param_range):\n",
    "    data = {'train_loss': [], 'train_accu': [], 'dev_accu': []}\n",
    "    for param in param_range:\n",
    "        hp = {param_name: param, 'dropout': 0.5}\n",
    "        _, plotting = tune(hp)\n",
    "        # record best dev accuracy\n",
    "        idx = np.argmax(plotting['dev_accu'])\n",
    "        for k in data:\n",
    "            data[k].append(plotting[k][idx])\n",
    "    #     plot_wer_loss(best, plotting)\n",
    "    plot_loss_accu(param_name, data, xlabel=param_name, xticks=param_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# experiment('dropout', [0.3, 0.5, 0.8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training DNN with config: hid512+n_layers1+dropout0.5\n",
      "Training time elapsed: 47.84 seconds\n",
      "Dev elapsed: 1.15 seconds\n",
      "Epoch: 0, Training loss: 2.07, Accuracy: 43.06, Dev Accuracy: 47.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruolinzheng/.local/lib/python3.5/site-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type FeedForward. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time elapsed: 47.53 seconds\n",
      "Dev elapsed: 1.15 seconds\n",
      "Epoch: 1, Training loss: 1.48, Accuracy: 56.79, Dev Accuracy: 48.06\n",
      "Training time elapsed: 47.03 seconds\n",
      "Dev elapsed: 1.14 seconds\n",
      "Epoch: 2, Training loss: 1.30, Accuracy: 61.08, Dev Accuracy: 51.93\n",
      "Training time elapsed: 47.96 seconds\n",
      "Dev elapsed: 1.14 seconds\n",
      "Epoch: 3, Training loss: 1.20, Accuracy: 64.13, Dev Accuracy: 50.95\n",
      "Training time elapsed: 47.06 seconds\n",
      "Dev elapsed: 1.15 seconds\n",
      "Epoch: 4, Training loss: 1.12, Accuracy: 66.30, Dev Accuracy: 50.56\n",
      "Training time elapsed: 47.04 seconds\n",
      "Dev elapsed: 1.15 seconds\n",
      "Epoch: 5, Training loss: 1.06, Accuracy: 68.07, Dev Accuracy: 51.01\n",
      "Training time elapsed: 47.23 seconds\n",
      "Dev elapsed: 1.14 seconds\n",
      "Epoch: 6, Training loss: 1.01, Accuracy: 69.45, Dev Accuracy: 49.93\n",
      "Training time elapsed: 46.41 seconds\n",
      "Dev elapsed: 1.14 seconds\n",
      "Epoch: 7, Training loss: 0.97, Accuracy: 70.60, Dev Accuracy: 49.16\n",
      "Training time elapsed: 46.93 seconds\n",
      "Dev elapsed: 1.15 seconds\n",
      "Epoch: 8, Training loss: 0.94, Accuracy: 71.50, Dev Accuracy: 51.27\n",
      "Training time elapsed: 48.03 seconds\n",
      "Dev elapsed: 1.14 seconds\n",
      "Epoch: 9, Training loss: 0.92, Accuracy: 72.42, Dev Accuracy: 50.76\n",
      "\n",
      "Best dev accuracy: 51.93 at epoch: 2\n",
      "\n",
      "Training DNN with config: hid512+n_layers2+dropout0.5\n",
      "Training time elapsed: 51.46 seconds\n",
      "Dev elapsed: 1.32 seconds\n",
      "Epoch: 0, Training loss: 2.11, Accuracy: 41.24, Dev Accuracy: 42.44\n",
      "Training time elapsed: 51.42 seconds\n",
      "Dev elapsed: 1.32 seconds\n",
      "Epoch: 1, Training loss: 1.48, Accuracy: 56.09, Dev Accuracy: 49.75\n",
      "Training time elapsed: 51.82 seconds\n",
      "Dev elapsed: 1.33 seconds\n",
      "Epoch: 2, Training loss: 1.27, Accuracy: 61.42, Dev Accuracy: 50.87\n",
      "Training time elapsed: 50.87 seconds\n",
      "Dev elapsed: 1.32 seconds\n",
      "Epoch: 3, Training loss: 1.14, Accuracy: 65.03, Dev Accuracy: 50.16\n",
      "Training time elapsed: 50.92 seconds\n",
      "Dev elapsed: 1.32 seconds\n",
      "Epoch: 4, Training loss: 1.05, Accuracy: 67.69, Dev Accuracy: 49.94\n",
      "Training time elapsed: 50.81 seconds\n",
      "Dev elapsed: 1.32 seconds\n",
      "Epoch: 5, Training loss: 0.98, Accuracy: 69.77, Dev Accuracy: 48.28\n",
      "Training time elapsed: 50.90 seconds\n",
      "Dev elapsed: 1.33 seconds\n",
      "Epoch: 6, Training loss: 0.92, Accuracy: 71.59, Dev Accuracy: 49.94\n",
      "Training time elapsed: 50.89 seconds\n",
      "Dev elapsed: 1.33 seconds\n",
      "Epoch: 7, Training loss: 0.88, Accuracy: 73.02, Dev Accuracy: 48.83\n",
      "Training time elapsed: 52.87 seconds\n",
      "Dev elapsed: 1.38 seconds\n",
      "Epoch: 8, Training loss: 0.85, Accuracy: 74.13, Dev Accuracy: 49.16\n",
      "Training time elapsed: 51.56 seconds\n",
      "Dev elapsed: 1.34 seconds\n",
      "Epoch: 9, Training loss: 0.81, Accuracy: 75.28, Dev Accuracy: 48.26\n",
      "\n",
      "Best dev accuracy: 50.87 at epoch: 2\n",
      "\n",
      "Training DNN with config: hid512+n_layers3+dropout0.5\n",
      "Training time elapsed: 54.91 seconds\n",
      "Dev elapsed: 1.51 seconds\n",
      "Epoch: 0, Training loss: 2.18, Accuracy: 39.44, Dev Accuracy: 46.75\n",
      "Training time elapsed: 54.37 seconds\n",
      "Dev elapsed: 1.51 seconds\n",
      "Epoch: 1, Training loss: 1.51, Accuracy: 55.02, Dev Accuracy: 46.65\n",
      "Training time elapsed: 54.39 seconds\n",
      "Dev elapsed: 1.50 seconds\n",
      "Epoch: 2, Training loss: 1.31, Accuracy: 60.15, Dev Accuracy: 49.44\n",
      "Training time elapsed: 54.65 seconds\n",
      "Dev elapsed: 1.48 seconds\n",
      "Epoch: 3, Training loss: 1.18, Accuracy: 63.87, Dev Accuracy: 49.07\n",
      "Training time elapsed: 53.74 seconds\n",
      "Dev elapsed: 1.51 seconds\n",
      "Epoch: 4, Training loss: 1.10, Accuracy: 66.39, Dev Accuracy: 47.73\n",
      "Training time elapsed: 54.65 seconds\n",
      "Dev elapsed: 1.50 seconds\n",
      "Epoch: 5, Training loss: 1.03, Accuracy: 68.61, Dev Accuracy: 47.27\n",
      "Training time elapsed: 54.34 seconds\n",
      "Dev elapsed: 1.49 seconds\n",
      "Epoch: 6, Training loss: 0.98, Accuracy: 70.23, Dev Accuracy: 47.06\n",
      "Training time elapsed: 54.88 seconds\n",
      "Dev elapsed: 1.50 seconds\n",
      "Epoch: 7, Training loss: 0.95, Accuracy: 71.21, Dev Accuracy: 46.75\n",
      "Training time elapsed: 54.83 seconds\n",
      "Dev elapsed: 1.50 seconds\n",
      "Epoch: 8, Training loss: 0.93, Accuracy: 72.28, Dev Accuracy: 46.30\n",
      "Training time elapsed: 54.89 seconds\n",
      "Dev elapsed: 1.51 seconds\n",
      "Epoch: 9, Training loss: 0.92, Accuracy: 72.94, Dev Accuracy: 46.96\n",
      "\n",
      "Best dev accuracy: 49.44 at epoch: 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiment('n_layers', [1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save log-emission probabilities using the best model saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_emission(utt_to_frames_dict, features, prior, temp_parameter, best_model_path):\n",
    "    \"\"\"\n",
    "    Save posteriors using the trained model\n",
    "    \"\"\"\n",
    "    classifier_eval = torch.load(best_model_path)\n",
    "    classifier_eval.eval()\n",
    "    log_emission = []\n",
    "    n_iter = 0\n",
    "    for utt_idx in range(len(utt_to_frames_dict)):\n",
    "        frame_id = utt_to_frames_dict[utt_idx]\n",
    "        log_emission_utt = []\n",
    "        for i in range(0, len(frame_id), batch_size):\n",
    "            idx = frame_id[i:i+batch_size]\n",
    "            Xs = torch.tensor(itemgetter(*idx)(features), dtype=torch.float32).to(device)\n",
    "            log_pred_Ys = F.log_softmax(classifier_eval(Xs), dim=1).cpu().data.numpy()\n",
    "            log_emission_utt.append(log_pred_Ys  - temp_parameter*np.log(prior))\n",
    "        log_emission_utt = np.concatenate(log_emission_utt, axis=0)\n",
    "        log_emission.append(log_emission_utt)\n",
    "\n",
    "    return log_emission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_log_emission(temp_parameter=None):\n",
    "    if temp_parameter is None:\n",
    "        temp_parameter = out_cfg[\"temp_parameter\"]\n",
    "    print(\"Saving log emissions for temperature %.1f ...\\n\" % (temp_parameter))\n",
    "    prior = data_ldr.get_prior()\n",
    "    train_log_emission =  get_log_emission(train_utt_to_frames, train_features, prior, temp_parameter, save_model_fn)\n",
    "    dev_log_emission = get_log_emission(dev_utt_to_frames, dev_features, prior, temp_parameter, save_model_fn)\n",
    "    test_log_emission = get_log_emission(test_utt_to_frames, test_features, prior, temp_parameter, save_model_fn)\n",
    "    log_emission_dict = {'Ytrain': train_log_emission, 'Ydev': dev_log_emission, 'Ytest': test_log_emission}\n",
    "    np.savez_compressed(os.path.join('hybrid/data/log_emission/log_emission_'+str(temp_parameter)+'.npz'), **log_emission_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving log emissions for temperature 1.0 ...\n",
      "\n",
      "Saving log emissions for temperature 0.5 ...\n",
      "\n",
      "Saving log emissions for temperature 0.0 ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "save_log_emission() # 1.0\n",
    "save_log_emission(temp_parameter=0.5)\n",
    "save_log_emission(temp_parameter=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HMM inference using the posterior from neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_wer(model, posterior=None):\n",
    "    test_wer = model.test(data_multiple_digit[\"Xtest\"], data_multiple_digit[\"Ytest\"], posterior)\n",
    "    print(\"{:.2f}% TEST WER\".format(test_wer * 100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_multiple_digit = np.load(\"hybrid/data/mfccs/mfccs_multiple.npz\", allow_pickle=True)\n",
    "\n",
    "with open(\"hybrid/hmm/models/multiple_digit_model.pkl\", \"rb\") as f:\n",
    "    full_model_trained = pkl.load(f)\n",
    "\n",
    "log_emission_1 = np.load('hybrid/data/log_emission/log_emission_1.0.npz', allow_pickle=True)\n",
    "log_emission_0 = np.load('hybrid/data/log_emission/log_emission_0.0.npz', allow_pickle=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline performance of the trained model\n",
      "24.55% TEST WER\n",
      "Performance of the trained model with normalized emission probabilities\n",
      "21.36% TEST WER\n",
      "Performance of the trained model with unnormalized emission probabilities\n",
      "19.09% TEST WER\n"
     ]
    }
   ],
   "source": [
    "print('Baseline performance of the trained model')\n",
    "get_test_wer(full_model_trained)\n",
    "\n",
    "print('Performance of the trained model with normalized emission probabilities')\n",
    "get_test_wer(full_model_trained, log_emission_1[\"Ytest\"])\n",
    "\n",
    "print('Performance of the trained model with unnormalized emission probabilities')\n",
    "get_test_wer(full_model_trained, log_emission_0[\"Ytest\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.55% TEST WER\n"
     ]
    }
   ],
   "source": [
    "log_emission_05 = np.load('hybrid/data/log_emission/log_emission_0.5.npz', allow_pickle=True)\n",
    "get_test_wer(full_model_trained, log_emission_05[\"Ytest\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
