{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "PLOT_CONFIG = { 'interpolation': \"nearest\", 'aspect': \"auto\", 'cmap': \"Greys\" }\n",
    "\n",
    "from IPython.display import Audio\n",
    "\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "\n",
    "from numpy.fft import fft, ifft\n",
    "from scipy.fftpack import dct, idct\n",
    "\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Feature extraction (Mel-Frequency Cepstral Coefficients)\n",
    "-------------------------------------------------\n",
    "- Explore the feature extraction pipeline\n",
    "\n",
    "### TODO:\n",
    "-----------\n",
    "- <strong>Finish the implementation of the 'discrete_fourier_transform' and compare the runtime speed with the 'fast_fourier_transform'.</strong>\n",
    "- <strong> Convert the yticks on plots from indices to frequencies or mels where specified by <em>TODO</em>.</strong>\n",
    "- Generate MFCCs and recover the orginal audio with the default settings (after implementing the DFT) by executing the cells below.\n",
    "- Play with the different settings of <em>size</em> (window size), <em>step</em> (window shift), <em>nfilters</em> (the number of filters in the mel-filterbank), and <em>ncoeffs</em> (the number of mel-frequency cepstral coefficients that are kept after feature extraction). Note that the process for inversion can be fragile, so it is best to try powers of 2 (e.g. <em>size</em> = [64, 128, 256, 512, 1024, ...] and <em>step</em> = [8, 16, 32, 64, 128, ...])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pre_emphasis(x):\n",
    "    \"\"\"\n",
    "    Applies pre-emphasis step to the signal.\n",
    "    - balance frequencies in spectrum by increasing amplitude of high frequency \n",
    "    bands and decreasing the amplitudes of lower bands\n",
    "    - largely unnecessary in modern feature extraction pipelines\n",
    "    ------\n",
    "    :in:\n",
    "    x, array of samples\n",
    "    ------\n",
    "    :out:\n",
    "    y, array of samples\n",
    "    \"\"\"\n",
    "    y = np.append(x[0], x[1:] - 0.97 * x[:-1])\n",
    "    \n",
    "    return y\n",
    "    \n",
    "def hamming(n):\n",
    "    \"\"\"\n",
    "    Hamming method for weighting components of window.\n",
    "    Feel free to implement more window functions.\n",
    "    ------\n",
    "    :in: \n",
    "    n, window size\n",
    "    ------\n",
    "    :out: \n",
    "    win, array of weights to apply along window\n",
    "    \"\"\"\n",
    "    win = 0.54 - .46 * np.cos(2 * np.pi * np.arange(n) / (n - 1))\n",
    "    \n",
    "    return win\n",
    "    \n",
    "def windowing(x, size, step):\n",
    "    \"\"\"\n",
    "    Window and stack signal into overlapping frames.\n",
    "    ------\n",
    "    :in:\n",
    "    x, array of samples\n",
    "    size, window size in number of samples (Note: this may need to be a power of 2)\n",
    "    step, window shift in number of samples\n",
    "    ------\n",
    "    :out:\n",
    "    frames, 2d-array of frames with shape (number of windows, window size)\n",
    "    \"\"\"\n",
    "    xpad = np.append(x, np.zeros((size - len(x) % size)))\n",
    "    \n",
    "    T = (len(xpad) - size) // step\n",
    "    frames = np.stack([xpad[t * step:t * step + size] for t in range(T)])\n",
    "    \n",
    "    return frames\n",
    "    \n",
    "def discrete_fourier_transform(x):\n",
    "    \"\"\"\n",
    "    Compute the discrete fourier transform for each frame of windowed signal x.\n",
    "    Typically, we talk about performing the DFT on short-time windows\n",
    "    (often referred to as the Short-Time Fourier Transform). Here, the input\n",
    "    is a 2d-array with shape (window size,  number of windows). We want to\n",
    "    perform the DFT on each of these windows.\n",
    "    Note: this can be done in a vectorized form or in a loop.\n",
    "    --------\n",
    "    :in: \n",
    "    x, 2d-array of frames with shape (window size, number of windows)\n",
    "    --------\n",
    "    :out:\n",
    "    X, 2d-array of complex spectrum after DFT applied to each window of x\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: Implement DFT\n",
    "\n",
    "    return X\n",
    "\n",
    "    \n",
    "def fast_fourier_transform(x):\n",
    "    \"\"\"\n",
    "    Fast-fourier transform. Effiicient algorithm for computing the DFT.\n",
    "    --------\n",
    "    :in: \n",
    "    x, 2d-array of frames with shape (window size, number of windows)\n",
    "    --------\n",
    "    :out:\n",
    "    X, 2d-array of complex spectrum after DFT applied to each window of x\n",
    "    \"\"\"\n",
    "    fft_size = len(x)\n",
    "\n",
    "    if fft_size <= 16:\n",
    "        X = discrete_fourier_transform(x)\n",
    "    \n",
    "    else:\n",
    "        indices = np.arange(fft_size)\n",
    "        even = fast_fourier_transform(x[::2])\n",
    "        odd = fast_fourier_transform(x[1::2])\n",
    "        m = np.exp(-2j * np.pi * indices / fft_size).reshape(-1, 1)\n",
    "        X = np.concatenate([even + m[:fft_size // 2] * odd, even + m[fft_size // 2:] * odd])\n",
    "    \n",
    "    return X\n",
    "\n",
    "\n",
    "def mel_filterbank(nfilters, fft_size, sample_rate):\n",
    "    \"\"\"\n",
    "    Mel-warping filterbank.\n",
    "    You do not need to edit this code; it is needed to contruct the mel filterbank\n",
    "    which we will use to extract features.\n",
    "    --------\n",
    "    :in: \n",
    "    nfilters, number of filters\n",
    "    fft_size, window size over which fft is performed\n",
    "    sample_rate, sampling rate of signal\n",
    "    --------\n",
    "    :out:\n",
    "    mel_filter, 2d-array of (fft_size / 2, nfilters) used to get mel features\n",
    "    mel_inv_filter, 2d-array of (nfilters, fft_size / 2) used to invert\n",
    "    melpoints, 1d-array of frequencies converted to mel-scale\n",
    "    \"\"\"\n",
    "    freq2mel = lambda f: 2595. * np.log10(1 + f / 700.)\n",
    "    mel2freq = lambda m: 700. * (10**(m / 2595.) - 1)\n",
    "\n",
    "    lowfreq = 0\n",
    "    highfreq = sample_rate // 2\n",
    "\n",
    "    lowmel = freq2mel(lowfreq)\n",
    "    highmel = freq2mel(highfreq)\n",
    "\n",
    "    melpoints = np.linspace(lowmel, highmel, 1 + nfilters + 1)\n",
    "\n",
    "    # must convert from freq to fft bin number\n",
    "    fft_bins = ((fft_size + 1) * mel2freq(melpoints) // sample_rate).astype(np.int32)\n",
    "\n",
    "    filterbank = np.zeros((nfilters, fft_size // 2))\n",
    "    for j in range(nfilters):\n",
    "        for i in range(fft_bins[j], fft_bins[j + 1]):\n",
    "            filterbank[j, i] = (i - fft_bins[j]) / (fft_bins[j + 1] - fft_bins[j])\n",
    "        for i in range(fft_bins[j + 1], fft_bins[j + 2]):\n",
    "            filterbank[j, i] = (fft_bins[j + 2] - i) / (fft_bins[j + 2] - fft_bins[j + 1])\n",
    "\n",
    "    mel_filter = filterbank.T / filterbank.sum(axis=1).clip(1e-16)\n",
    "    mel_inv_filter = filterbank\n",
    "\n",
    "    return mel_filter, mel_inv_filter, melpoints\n",
    "    \n",
    "    \n",
    "def inv_spectrogram(X_s, size, step, n_iter=15):\n",
    "    \"\"\"\n",
    "    Feel free to disregard this code. It is not necessary that\n",
    "    you follow the code below, but it can be used to invert\n",
    "    from the spectrogram (signal spectrum magnitude) back to the signal\n",
    "    which can be helpful when qualitatively assessing the nature of\n",
    "    compression into MFCC features.\n",
    "    \"\"\"\n",
    "    \n",
    "    def find_offset(a, b):\n",
    "        corrs = np.convolve(a - a.mean(), b[::-1] - b.mean())\n",
    "        corrs[:len(b) // 2] = -1e12\n",
    "        corrs[-len(b) // 2:] = -1e12\n",
    "        return corrs.argmax() - len(a)\n",
    "\n",
    "    def iterate(X, iteration):\n",
    "        T, n = X.shape\n",
    "        size = n // 2\n",
    "\n",
    "        x = np.zeros((T * step + size))\n",
    "        window_sum = np.zeros((T * step + size))\n",
    "\n",
    "        est_start = size // 2 - 1\n",
    "        est_stop = est_start + size\n",
    "\n",
    "        for t in range(T):\n",
    "            x_start = t * step\n",
    "            x_stop = x_start + size\n",
    "\n",
    "            est = ifft(X[t].real + 0j if iteration == 0 else X[t]).real[::-1]            \n",
    "            if t > 0 and x_stop - step > x_start and est_stop - step > est_start:\n",
    "                offset = find_offset(x[x_start:x_stop - step], est[est_start:est_stop - step])\n",
    "            else:\n",
    "                offset = 0\n",
    "                \n",
    "            x[x_start:x_stop] += est[est_start - offset:est_stop - offset] * hamming(size)\n",
    "            window_sum[x_start:x_stop] += hamming(size)\n",
    "\n",
    "        return x.real / window_sum.clip(1e-12)\n",
    "\n",
    "    X_s = np.concatenate([X_s, X_s[:, ::-1]], axis=1)\n",
    "    reg = np.max(X_s) / 1e8\n",
    "\n",
    "    X_best = iterate(deepcopy(X_s), 0)\n",
    "    for i in range(1, n_iter):\n",
    "        X_best = windowing(X_best, size, step) * hamming(size)\n",
    "        est = fast_fourier_transform(X_best.T).T\n",
    "        phase = est / np.maximum(reg, np.abs(est))\n",
    "        X_best = iterate(X_s * phase[:len(X_s)], i)\n",
    "    \n",
    "    return np.real(X_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original signal\n",
    "signal, fs = sf.read('aurora_FMS_15739A.wav')\n",
    "Audio(data=signal, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-emphasized signal\n",
    "Audio(data=pre_emphasis(signal), rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the runtime of your discrete fourier transform against the fast fourier transform\n",
    "\n",
    "# with a window size of 128 and a step of 32\n",
    "frames128 = windowing(signal, 128, 64) * hamming(128)\n",
    "%timeit -n 50 discrete_fourier_transform(frames128.T).T\n",
    "%timeit -n 50 fast_fourier_transform(frames128.T).T\n",
    "\n",
    "# check that the discrete_fourier_transform is correct\n",
    "# NOTE: the difference in shape (transpose or not transpose) between our implementation and numpy's\n",
    "print(\"Is DFT correct?\", np.allclose(fft(frames128), discrete_fourier_transform(frames128.T).T, atol=1e-12))\n",
    "print(\"Is FFT correct?\", np.allclose(fft(frames128), fast_fourier_transform(frames128.T).T, atol=1e-12))\n",
    "\n",
    "# with a window size of 512 and a step of 32\n",
    "frames512 = windowing(signal, 512, 256) * hamming(512)\n",
    "%timeit -n 50 discrete_fourier_transform(frames512.T).T\n",
    "%timeit -n 50 fast_fourier_transform(frames512.T).T\n",
    "\n",
    "# with a window size of 2048 and a step of 32\n",
    "frames2048 = windowing(signal, 2048, 1024) * hamming(2048)\n",
    "%timeit -n 50 discrete_fourier_transform(frames2048.T).T\n",
    "%timeit -n 50 fast_fourier_transform(frames2048.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 128 # window size for the FFT\n",
    "step = size // 2 # distance to slide along the window in time\n",
    "nfilters = 26 # number of mel frequency channels\n",
    "ncoeffs = 13 # number of cepstral coeffecients to keep\n",
    "\n",
    "# pre-emphasize signal\n",
    "pre_emphasized_signal = pre_emphasis(signal)\n",
    "\n",
    "# window signal\n",
    "frames = windowing(pre_emphasized_signal, size, step) * hamming(size)\n",
    "\n",
    "# compute complex spectrum\n",
    "spectrum = fast_fourier_transform(frames.T).T\n",
    "spectrum = spectrum[:, :size // 2] # only need to keep half since it's symmetric\n",
    "\n",
    "# compute spectrum magnitude (typically what is meant by spectrogram)\n",
    "magnitude = np.abs(spectrum)\n",
    "\n",
    "# get spectrum power\n",
    "power = magnitude**2 / size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize log spectrogram (dB)\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(18,4))\n",
    "cax = ax.matshow(20*np.log10(magnitude.clip(1e-12)).T, origin='lower', **PLOT_CONFIG)\n",
    "fig.colorbar(cax, label='dB')\n",
    "plt.title('log spectrogram (dB)')\n",
    "plt.xlabel('# Frames')\n",
    "plt.ylabel('Indices')\n",
    "\n",
    "# TODO: yticks as frequencies\n",
    "# ----------------------------\n",
    "# plt.ylabel('Hz')\n",
    "# plt.yticks(indices, frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate the mel filter and mel inverse filter\n",
    "mel_filter, mel_inv_filter, melpoints = mel_filterbank(nfilters, size, fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the mel filter\n",
    "fig, ax = plt.subplots(nrows=1,ncols=1, figsize=(20,4))\n",
    "ax.matshow(mel_filter.T, **PLOT_CONFIG)\n",
    "ax.set_title('mel filter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize log mel spectrogram (dB) (Note: striations corresponding to filters with 0 above)\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(18,4))\n",
    "cax = ax.matshow(20*np.log10(magnitude.dot(mel_filter).clip(1e-16)).T, origin='lower', **PLOT_CONFIG)\n",
    "fig.colorbar(cax, label='dB')\n",
    "plt.title('log mel spectrogram (dB)')\n",
    "plt.xlabel('# Frames')\n",
    "plt.ylabel('Indices (Filter #)')\n",
    "\n",
    "# TODO: yticks as mels\n",
    "# ----------------------------\n",
    "# plt.ylabel('Mel')\n",
    "# plt.yticks(indices, mels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply mel warping filters to power spectrum and take log10\n",
    "log_mel_fbank = np.log10(power.dot(mel_filter).clip(1e-16))\n",
    "\n",
    "# compute MFCCs using discrete cosine transform\n",
    "\"\"\"\n",
    "Note: DCT is used to decompose a finite discrete-time vector\n",
    "into a sum of scaled-and-shifted (real-valued) cosine functions\n",
    "(this can be thought of similarly to the DFT); additionally,\n",
    "the DCT often has better compression qualities as its top coefficients\n",
    "tend to by largely decorrelated, which can improve our position when\n",
    "make modeling assumptions later on\n",
    "\"\"\"\n",
    "mfccs = dct(log_mel_fbank, type=2, axis=1, norm='ortho')\n",
    "\n",
    "# keep subset of cepstral coefficients\n",
    "mfccs = mfccs[:,:ncoeffs]\n",
    "\n",
    "# Visualize (normalized) MFCCs\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(18,4))\n",
    "cax = ax.matshow(mfccs.T, origin='lower', **PLOT_CONFIG)\n",
    "fig.colorbar(cax)\n",
    "plt.title('MFCCs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert from MFCCs back to waveform\n",
    "recovered_log_mel_fbank = idct(mfccs, type=2, n=nfilters, axis=1, norm='ortho')\n",
    "\n",
    "# exponentiate log and invert mel warping\n",
    "recovered_power = (10**recovered_log_mel_fbank).dot(mel_inv_filter)\n",
    "\n",
    "# invert mel warping of spectrogram\n",
    "recovered_magnitude = np.sqrt(recovered_power * size)\n",
    "\n",
    "# Look at specgram\n",
    "fig, ax = plt.subplots(nrows=1,ncols=1, figsize=(18,4))\n",
    "cax = ax.matshow(20*np.log10(recovered_magnitude.clip(1e-12)).T, origin='lower', **PLOT_CONFIG)\n",
    "fig.colorbar(cax, label='dB')\n",
    "plt.title('log spectrogram recovered from MFCCS (dB)')\n",
    "plt.xlabel('# Frames')\n",
    "plt.ylabel('Indices')\n",
    "\n",
    "# TODO: yticks as frequencies\n",
    "# ----------------------------\n",
    "# plt.ylabel('Hz')\n",
    "# plt.yticks(indices, frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recovered_signal = inv_spectrogram(recovered_magnitude, size, step)\n",
    "Audio(data=recovered_signal, rate=fs)  #(Note: preemphasis is not inverted in resynthesizing the speech)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Single Digit Recognition\n",
    "-------------------------------------------------\n",
    "- Use MFCC features along with the Dynamic Time Warping algorithm to perform single digit recognition. This routine uses MFCC features and aligns each test utterance against training templates of each digit to make a prediction.\n",
    "\n",
    "### TODO:\n",
    "-----------\n",
    "- <strong>Finish the implementation of the 'dtw' function below by implementing the recursion step (for computing the minimum distance) and the traceback step to (for finding a minimizing path) which are both <em>marked by TODO</em>. Use the move set introduced in class:</strong>\n",
    "![Move Set](figures/move_set.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 256 # window size for the FFT\n",
    "step = size // 2 # distance to slide along the window in time\n",
    "nfilters = 40 # number of mel frequency channels\n",
    "ncoeffs = 13 # number of cepstral coeffecients to keep\n",
    "mel_filter, _, _ = mel_filterbank(nfilters, size, sample_rate=8000) # mel filters for use below\n",
    "\n",
    "def dist(a, b):\n",
    "    \"\"\"\n",
    "    Compute the Euclidean distance between a and b.\n",
    "    --------\n",
    "    :in:\n",
    "    a : 1d-array (frame of MFCCs)\n",
    "    b : 1d-array (frame of MFCCs)\n",
    "    --------\n",
    "    :out:\n",
    "    d, distance between a and b\n",
    "    \"\"\"\n",
    "    d = np.sum((a - b)**2)\n",
    "    return d\n",
    "\n",
    "def dtw(x, y, dist):\n",
    "    \"\"\"\n",
    "    Dynamic time warping function.\n",
    "    Method to compute distance between\n",
    "    two segments that differ in length.\n",
    "    --------\n",
    "    :in:\n",
    "    x : sequence of MFCC frames (2d-array with shape (Tx, 13)\n",
    "    y : sequence of MFCC frames (2d-array with shape (Ty, 13)\n",
    "    dist: function to compute the distance between a frame of x and a frame of y\n",
    "    --------\n",
    "    :out:\n",
    "    d, distance between frame sequences x and y (scalar)\n",
    "    \"\"\" \n",
    "    D = np.zeros((len(x), len(y)))\n",
    "    for i in range(len(x)):\n",
    "        for j in range(len(y)):\n",
    "            D[i, j] = dist(x[i], y[j])\n",
    "    \n",
    "    c = deepcopy(D)\n",
    "    for i in range(len(x)):\n",
    "        for j in range(len(y)):\n",
    "            if i == 0 and j == 0:\n",
    "                continue\n",
    "            else:    \n",
    "                if i == 0:\n",
    "                    D[i, j] += # TODO: edge case\n",
    "                elif j == 0:\n",
    "                    D[i, j] += # TODO: edge case\n",
    "                else:\n",
    "                    D[i, j] += # TODO: general case/recursive step, min(..., ..., ...)\n",
    "    \n",
    "    i, j = len(x) - 1, len(y) - 1\n",
    "    x, y = [i], [j]\n",
    "    while True:\n",
    "\n",
    "        if i == 0 and j == 0: # then we're done\n",
    "            break\n",
    "        else: # figure out which move to traceback\n",
    "            if i == 0:\n",
    "                tb = # TODO: edge case\n",
    "            elif j == 0:\n",
    "                tb = # TODO: edge case\n",
    "            else:\n",
    "                tb = # TODO: general case/traceback minimizing path\n",
    "\n",
    "        # after tracing back the correct move, update the position on the path\n",
    "        if tb == 0:\n",
    "            # TODO: update i,j coordinates when tracing back move 0\n",
    "        elif tb == 1:\n",
    "            # TODO: update i,j coordinates when tracing back move 1\n",
    "        else:\n",
    "            # TODO: update i,j coordinates when tracing back move 2\n",
    "\n",
    "        x.insert(0, i)\n",
    "        y.insert(0, j)\n",
    "    \n",
    "    path = (x, y)        \n",
    "    d = D[-1, -1] / np.sum(D.shape)\n",
    "    return d, path, c\n",
    "\n",
    "    \n",
    "def extract_mfcc_features(signal, rate):\n",
    "    \"\"\"\n",
    "    MFCC feature extraction.\n",
    "    This function is concise representation of the process you started with above.\n",
    "    This function will be used to extract features from tidgits examples (Downloaded from canvas)\n",
    "    to perform a simple single digit recognition task.\n",
    "    --------\n",
    "    :in:\n",
    "    signal : array of audio samples\n",
    "    rate   : sampling rate\n",
    "    --------\n",
    "    :return: normalized mfcc features (number of frames, number of cepstral coefficients)\n",
    "    \"\"\"\n",
    "    \n",
    "    # pre-emphasize signal\n",
    "    pre_emphasized_signal = pre_emphasis(signal)\n",
    "    \n",
    "    # window signal\n",
    "    frames = windowing(pre_emphasized_signal, size, step) * hamming(size)\n",
    "\n",
    "    # compute complex spectrum (Note: this produces symmetric output, only need first half)\n",
    "    spectrum = fast_fourier_transform(frames.T).T\n",
    "    spectrum = spectrum[:, :size // 2]\n",
    "\n",
    "    # compute spectrum magnitude (typically what is meant by spectrogram)\n",
    "    magnitude = np.abs(spectrum)\n",
    "\n",
    "    # get spectrum power\n",
    "    power = magnitude**2 / size\n",
    "\n",
    "    # apply mel warping filters to power spectrum and take log10\n",
    "    log_mel_fbank = np.log10(power.dot(mel_filter).clip(1e-16))\n",
    "\n",
    "    # compute MFCCs using discrete cosine transform\n",
    "    mfccs = dct(log_mel_fbank, type=2, axis=1, norm='ortho')\n",
    "    \n",
    "    # keep only first 'ncoeffs' cepstral coefficients\n",
    "    mfccs = mfccs[:,:ncoeffs]\n",
    "    \n",
    "    return mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def single_digit_recognition(num_templates, dist):\n",
    "    \"\"\"\n",
    "    Single digit recognizer.\n",
    "    Use DTW-distance to a set of training templates per digit\n",
    "    to predict which digit class each test example belows to.\n",
    "    ---------\n",
    "    :in:\n",
    "    num_templates, number of training templates to compare with\n",
    "    dist, distance function to be used by DTW (defaults to Euclidean distance)\n",
    "    ---------\n",
    "    :out:\n",
    "    accuracy, overall digit accuracy\n",
    "    confusion, confusion matrix showing heatmap of digit groundtruth/prediction pairs\n",
    "    \"\"\"\n",
    "    digits = range(10)\n",
    "\n",
    "    templates = defaultdict(list)\n",
    "    for digit in digits:\n",
    "        for i, wav in enumerate(glob('tidigits/train/*/%sa.wav' % ('o' if digit == 0 else str(digit)))):\n",
    "            if i < num_templates:\n",
    "                mfccs = extract_mfcc_features(*sf.read(wav))\n",
    "                templates[digit].append(mfccs)\n",
    "\n",
    "    accuracy, confusion = np.zeros((10)), np.zeros((10, 10))\n",
    "\n",
    "    for digit in digits:\n",
    "        correct, total = 0., 0.\n",
    "        for wav in glob('tidigits/test/*/%sa.wav' % ('o' if digit == 0 else str(digit))):\n",
    "            x = extract_mfcc_features(*sf.read(wav))\n",
    "            comparisons = []\n",
    "            for i in digits:\n",
    "                distance = sum([dtw(x, y, dist)[0] for y in templates[i]])\n",
    "                comparisons.append((i, distance))\n",
    "            top_digit, _ = sorted(comparisons, key=lambda x: x[1])[0]\n",
    "            confusion[digit, top_digit] += 1.\n",
    "        accuracy[digit] = confusion[digit, digit] / confusion[digit].sum()\n",
    "\n",
    "    return np.mean(accuracy), confusion / confusion.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform single digit recognition using your dtw function and feature extraction\n",
    "# Note: this will take about 1 min with the default settings for part 2 above\n",
    "# --- size = 512\n",
    "# --- step = size // 2\n",
    "# --- nfilters = 40\n",
    "# --- ncoeffs = 13\n",
    "# If you would like to speed up training you can subsample the sequences of MFCCs\n",
    "# (e.g. mfccs[::5] to get every fifth frame and cut the length to T/5). Without\n",
    "# subsampling, the one template example takes ~55s on the speech cube machine.\n",
    "acc, confusion = single_digit_recognition(num_templates=1, dist=dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize confusion matrix\n",
    "plt.matshow(confusion)\n",
    "plt.title('Digit confusion (acc=%.2f' % (acc * 100.) + '%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the DTW paths for two examples of the same digit class\n",
    "same_digitA = 'tidigits/test/bc/1a.wav'\n",
    "same_digitB = 'tidigits/train/ae/1a.wav'\n",
    "a = extract_mfcc_features(*sf.read(same_digitA))\n",
    "b = extract_mfcc_features(*sf.read(same_digitB))\n",
    "min_dist, best_path, cost = dtw(a, b, dist)\n",
    "\n",
    "plt.imshow(cost.T, origin='lower', cmap=plt.cm.Reds, interpolation='nearest', aspect='auto')\n",
    "plt.plot(best_path[0], best_path[1], '-o')\n",
    "plt.xlabel(same_digitA)\n",
    "plt.ylabel(same_digitB)\n",
    "plt.axis('tight')\n",
    "plt.title('Minimum distance: {}'.format(min_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the DTW paths for two examples of different digit classes\n",
    "diff_digitA = 'tidigits/test/bc/1a.wav'\n",
    "diff_digitB = 'tidigits/train/ae/6a.wav'\n",
    "a = extract_mfcc_features(*sf.read(diff_digitA))\n",
    "b = extract_mfcc_features(*sf.read(diff_digitB))\n",
    "min_dist, best_path, cost = dtw(a, b, dist)\n",
    "\n",
    "plt.imshow(cost.T, origin='lower', cmap=plt.cm.Reds, interpolation='nearest', aspect='auto')\n",
    "plt.plot(best_path[0], best_path[1], '-o')\n",
    "plt.xlabel(diff_digitA)\n",
    "plt.ylabel(diff_digitB)\n",
    "plt.axis('tight')\n",
    "plt.title('Minimum distance: {}'.format(min_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
